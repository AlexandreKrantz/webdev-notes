✅=> understanding, check. notes ready for memorization & practice. 

- L1-2: comp250 review (time complexity and recurrences) ✅✅
	- Data structure vs. data type
- L2-3: hash table, hash functions, collision resolution ✅
	- Big omega vs. big O vs. big theta (formal def.)
	- running time of primitive operations
	- solving recurrences 
	- formula for finite geometric series
	- key vs. hash value vs. hash code
	- division method vs. multiplication method for hash functions
	- universal hashing
	- chaining method explanation + expected case analysis + time complexity for basic data structure operations
	- open addressing explanation 
		+ linear vs. quadratic probing vs. double hashing 
		+ expected number of probes in successful vs. unsuccessful search
- L4: disjoint sets ADT, union find Algo ✅
	- properties of an equivalence relation + correspondance to graphs
	- how is disjoint set implemented (relation to equivalence relation)
	- **depth** of a node in a tree vs. **height** of a node in a tree
		- [algorithm - What is the difference between tree depth and height? - Stack Overflow](https://stackoverflow.com/questions/2603692/what-is-the-difference-between-tree-depth-and-height)
	- runtime of union find
		- union *by size* or *by height*
	- path compression
- L5: max-heap, min-heap (construction), heapsort ✅
	- min vs. max-heap
	- maxheapify function + time complexity
	- inserting into a heap + time complexity
	- building a heap + time complexity
	- heapsort + time complexity
- L6: binary search tree, AVL tree ✅
	- what is a binary search tree? time complexity of search, insert, delete. 
	- balanced vs unbalanced BST
	- in-order traversal 
	- Sorting arrays with BST + time complexity
	- Definition of AVL tree + time complexity of DS ops. 
	- Pseudocode for AVL `insert` and `delete`
	- def. **balance factor**
- L7: red-black trees ✅
	- conditions 
	- time complexity DS ops
	- how do the `insert` & `delete` operations work - practice with examples
- L8: programming paradigms ✅
	- complete search + give example
	- recursive backtracking (==method template==)
- L9-10: divide and conquer ✅
	- general template 
	- describe mergesort
	- time complexity ==master method??==
- L11-13: dynamic programming ✅
	- what's the gist of DP?
	- def. memoization, tabulation, bottom up, top down
- L13-14: greedy
- L5: graphs ✅
	- When do we say a graph is **dense** vs. **sparse**?
	- When is a graph **strongly connected**? What's the condition for a graph to be a tree?
	- Describe BFS (queue) + time complexity 
	- Describe DFS (stack) + time complexity
	- (def. *tree edge* vs. *back edge* vs. *forward edge* etc?)
	- Directed acyclic graph (source, sink); what type of edge can this graph not have?
- L16: topological sort, strongly connected components ✅
	- Topological sort (basic idea + DFS algorithm) + time complexity
	- When do we say a graph G is *strongly connected*?
	- How can we make a DAG from stronly connected components 
- L17-18: flow networks ✅
	- describe the point of a flow network graph
	- describe the ford-fulkerson method : [[Flow Networks#Better Algorithm- The Ford-Fulkerson Method]]
	- what is a "cut" of a graph? how de we calculate the "value" of a cut?
	- max-flow min-cut theorem
- L19: single source shortest paths ✅
	- what does "single source" mean 
		- how do use SSSP to get "single-destination", "single-pair", "all pairs".  
	- What kind of graph can you run SSSP on
	- Describe BFS algorithm 
- L20: minimum spanning trees ✅
- L21: bipartite graphs ✅
- L22: amortized analysis ✅
- L23-24: random and probabilistic ✅

Prove invariant conditions:
1. Initialization (condition true at the beginning?)
2. Maintenance (condition true during an arbitrary loop iteration?)
3. Termination (condition true at the end?)

